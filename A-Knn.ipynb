{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unknown_data_path = './data/2_rf_test_unknown_data.csv'\n",
    "test_unknown_data = pd.read_csv(test_unknown_data_path)\n",
    "\n",
    "test_unknown_label_path = './data/2_rf_test_unknown_label.csv'\n",
    "test_unknown_label = pd.read_csv(test_unknown_label_path)\n",
    "\n",
    "print(\"test_unknown_data shape:\", test_unknown_data.shape)\n",
    "print(\"test_unknown_data shape:\", test_unknown_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf_26 = KNeighborsClassifier(n_neighbors=26)\n",
    "knn_clf_20 = KNeighborsClassifier(n_neighbors=20)\n",
    "knn_clf_15 = KNeighborsClassifier(n_neighbors=15)\n",
    "knn_clf_10 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_clf_5 = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_list = []\n",
    "knn_list.append(knn_clf_26)\n",
    "knn_list.append(knn_clf_20)\n",
    "knn_list.append(knn_clf_15)\n",
    "knn_list.append(knn_clf_10)\n",
    "knn_list.append(knn_clf_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Assuming test_unknown_data is your test data\n",
    "# Drop the 'label' column from test_unknown_data\n",
    "#test_unknown_data = test_unknown_data.drop('label', axis=1)\n",
    "\n",
    "# Apply label encoding separately to each column in test_unknown_label\n",
    "label_encoder = LabelEncoder()\n",
    "test_unknown_label_encoded = label_encoder.fit_transform(test_unknown_label)\n",
    "\n",
    "# Train the kNN classifier on your training data\n",
    "# Use the appropriate labels from your dataset; I'm using the first column as an example\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "# Assuming your_training_data and your_training_labels are your original training data and labels\n",
    "knn_clf.fit(test_unknown_data, test_unknown_label.values.ravel())  \n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = knn_clf.predict(np.array(test_unknown_data))\n",
    "\n",
    "# Optionally, you can evaluate the performance of the classifier\n",
    "# Assuming y_true is the actual labels for evaluation\n",
    "accuracy = accuracy_score(test_unknown_label_encoded, predictions)\n",
    "print(f'Accuracy for kNN with {knn_clf.n_neighbors} neighbors: {accuracy}')\n",
    "\n",
    "# Loop through each kNN classifier in knn_list\n",
    "for knn_clf in knn_list:\n",
    "    # Train the kNN classifier on your training data\n",
    "    knn_clf.fit(test_unknown_data, test_unknown_label.values.ravel()) \n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = knn_clf.predict(np.array(test_unknown_data))\n",
    "\n",
    "    # Evaluate the performance of the classifier\n",
    "    accuracy = accuracy_score(test_unknown_label.values.ravel(), predictions)\n",
    "    \n",
    "    # Print the accuracy for each kNN classifier\n",
    "    print(f'Accuracy for kNN with {knn_clf.n_neighbors} neighbors: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "# Load test data and labels\n",
    "\n",
    "\n",
    "# Apply label encoding to the labels\n",
    "\n",
    "\n",
    "# Assuming knn_list is a list of KNN models with different k values\n",
    "#knn_list = [KNeighborsClassifier(n_neighbors=k) for k in [26, 20, 15, 10, 5]]\n",
    "\n",
    "# Specify the number of features to select\n",
    "#k_best = 2  \n",
    "\n",
    "# Remove features with low variance\n",
    "#selector = VarianceThreshold()\n",
    "#test_unknown_data_filtered = selector.fit_transform(test_unknown_data)\n",
    "\n",
    "# Apply SelectKBest with ANOVA F-statistic as the scoring function\n",
    "##selector = SelectKBest(f_classif, k=k_best)\n",
    "#selected_data = selector.fit_transform(test_unknown_data, test_unknown_label_encoded)\n",
    "##downsampled_size = 100\n",
    "#indices = np.random.choice(len(test_unknown_data), downsampled_size, replace=False) \n",
    "#downsampled_data = test_unknown_data.iloc[indices]\n",
    "#downsampled_labels = test_unknown_label.iloc[indices]\n",
    "#downsampled_labels_endoded = label_encoder.fit_transform(downsampled_labels)\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "#StandardScalar is used to reduce the size of the values to prevent memory error\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(test_unknown_data)\n",
    "reduced_data = pca.fit_transform(scaled_data)\n",
    "#reduced_data2=pca.fit_transform(downsampled_data)\n",
    "print(reduced_data.size)\n",
    "print(reduced_data)\n",
    "#print(reduced_data2.size)\n",
    "#print(reduced_data2)\n",
    "\n",
    "knn_list = [KNeighborsClassifier(n_neighbors=k) for k in [26, 20, 15, 10, 5]]\n",
    "\n",
    "\n",
    "def plot_decision_boundary(knn, X, y, title, ax):\n",
    "    h = 1  # Step size in the mesh\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Obtain predictions for each point in the meshgrid\n",
    "    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z_encoded = label_encoder.fit_transform(Z)\n",
    "    Z = Z_encoded.reshape(xx.shape)\n",
    "    print(xx.size, yy.size, Z.size)\n",
    "    for i in range(xx.shape[0]):\n",
    "        for j in range(xx.shape[1]):\n",
    "            print(f\"xx[{i}][{j}] = {xx[i][j]}, yy[{i}][{j}] = {yy[i][j]}, Z[{i}][{j}] = {Z[i][j]}\")\n",
    "\n",
    "    ax.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.3)\n",
    "\n",
    "    # Plot the training points\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
    "\n",
    "    ax.set_xlabel('Principal Component 1')\n",
    "    ax.set_ylabel('Principal Component 2')\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Set up subplots\n",
    "fig, axes = plt.subplots(1, len(knn_list), figsize=(15, 3))  # Adjust figsize as needed\n",
    "# Assuming downsampled_labels is defined somewhere in your code\n",
    "for i, (knn, k) in enumerate(zip(knn_list, [26, 20, 15, 10, 5])):\n",
    "    knn.fit(reduced_data, test_unknown_label_encoded)\n",
    "    plot_decision_boundary(knn, reduced_data, test_unknown_label_encoded, f'KNN Decision Boundaries (k={k})', axes[i])\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "\n",
    "# Generate synthetic data with 4 clusters using make_blobs\n",
    "X, y = make_blobs(n_samples=300, centers=4, random_state=42)\n",
    "\n",
    "# Apply label encoding to the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Specify the number of features to select\n",
    "k_best = 2  \n",
    "\n",
    "# Apply SelectKBest with ANOVA F-statistic as the scoring function\n",
    "selector = SelectKBest(f_classif, k=k_best)\n",
    "selected_data = selector.fit_transform(X, y_encoded)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "scaled_data = StandardScaler().fit_transform(selected_data)\n",
    "reduced_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Set up k-NN classifiers with different k values\n",
    "knn_list = [KNeighborsClassifier(n_neighbors=k) for k in [26, 20, 15, 10, 5]]\n",
    "\n",
    "def plot_decision_boundary(knn, X, y, title, ax):\n",
    "    h = 0.1  # Step size in the mesh\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Obtain predictions for each point in the meshgrid\n",
    "    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z_encoded = label_encoder.transform(Z)\n",
    "    Z = Z_encoded.reshape(xx.shape)\n",
    "    \n",
    "    ax.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.3)\n",
    "\n",
    "    # Plot the training points\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
    "\n",
    "    ax.set_xlabel('Principal Component 1')\n",
    "    ax.set_ylabel('Principal Component 2')\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Set up subplots\n",
    "fig, axes = plt.subplots(1, len(knn_list), figsize=(15, 3))  # Adjust figsize as needed\n",
    "\n",
    "# Plot decision boundaries for each k-NN classifier\n",
    "for i, (knn, k) in enumerate(zip(knn_list, [26, 20, 15, 10, 5])):\n",
    "    knn.fit(reduced_data, y_encoded)\n",
    "    plot_decision_boundary(knn, reduced_data, y_encoded, f'KNN Decision Boundaries (k={k})', axes[i])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
